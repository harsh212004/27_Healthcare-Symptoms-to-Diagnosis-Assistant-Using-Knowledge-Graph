Project summary

This repository implements a hybrid symptom-to-diagnosis system that combines a Knowledge Graph (disease↔symptom relationships) with a LightGBM classifier. The pipeline:

Parses a disease→symptom dataset (with per-symptom probabilities).

Builds a NetworkX knowledge graph with weighted edges.

Computes symptom importance scores.

Generates a large training set of symptom combinations and engineered numeric features.

Trains a LightGBM classifier on TF-IDF (1–3 gram) + numeric features.

Implements a hybrid inference engine that fuses KG evidence and ML probabilities using match-level fallback (4→3→2), rank boosts, and consensus bonuses.

Produces a condensed diagnostic report (top predictions, confidence, KG/ML split, matched symptoms).

This approach aims for accuracy + interpretability — the KG provides traceable reasons and the ML provides coverage for noisy / ambiguous inputs.

Repository structure (key files)

main.py (or the script you are running) — contains the full pipeline: parsing, KG build, feature generation, training, and inference helpers.

final_disease_symptoms_trimmed.json — primary dataset file (expected in same folder).

lightgbm_knowledge_graph.png — saved KG visualization (generated by script).

README.md — this file.

(Optional) artifacts/ — directory to save serialized models and vectorizers if you add persistence.

Reference uploaded project report (if needed):
/mnt/data/30_Relative Scoring-Based Resume Analyser Using Natural Language Processing (1) (1).pdf

Note: Adjust paths above as needed. The code expects final_disease_symptoms_trimmed.json to be present.

Requirements

Tested with Python 3.10+ (but 3.8+ should work). Install packages with pip:

pip install numpy pandas networkx matplotlib scikit-learn scipy lightgbm


Minimal package list:

numpy

pandas

networkx

matplotlib

scikit-learn

scipy

lightgbm

You may also want Jupyter / IPython for interactive runs.

How to run (Quick start)

Put final_disease_symptoms_trimmed.json in the project directory.

Run the main script (example):

python main.py


The script will:

Parse the JSON file

Build the KG

Generate the expanded training set (≈25k samples)

Fit LightGBM

Print performance metrics (Top-1, Top-3 accuracy, weighted F1)

Run several showcase diagnostic test cases and print condensed reports

Save a KG visualization lightgbm_knowledge_graph.png to disk

Important: The training and data generation steps are CPU-bound and may take time. You can comment out data generation/training if you only want to use precomputed artifacts.

Important functions / API (in-script usage)

You can import or call these functions if you modularize the code:

parse_symptoms(symptom_string) -> (symptoms, probs)

Parses a symptom string like "fever 0.52, cough 0.40" into lists of symptoms and their probabilities.

kg_predict_disease(symptoms_input, graph, required_count=3, top_k=20)

Performs strict KG reasoning (4→3→2 fallback) and returns KG candidates + match level.

Returns: (results_list, match_level)

hybrid_predict(symptoms_input, top_k=3)

Runs the full hybrid pipeline for an input symptom list.

Input: symptoms_input — list of symptom strings (e.g. ['abdominal pain','fever'])
Returns: a dictionary containing:

predictions: ranked list of (disease, score)

kg_contribution: per-disease KG scores (normalized)

ml_contribution: ML probability map

kg_details: matched symptom lists and weights

ml_confidence

weights: dictionary of final KG/ML weight used

match_level: fallback level (4/3/2/0)

diagnose_patient_condensed(symptoms_list, case_name="", case_emoji="", case_description="")

Formats and returns a human-friendly condensed diagnostic report with matched symptoms, KG/ML split, and confidence for the top predictions. Great for printing to console or embedding in a simple UI.

Example usage:

from main import diagnose_patient_condensed

case = diagnose_patient_condensed(
    ['abdominal pain', 'nausea', 'vomiting', 'fever', 'loss of appetite', 'rebound tenderness'],
    case_name="Sample Case - Abdominal Pain",
    case_description="Severe abdominal pain with GI symptoms"
)
print(case['table_data'])

Expected outputs

Console output with formatted diagnostic test cases (as shown in your script).

lightgbm_knowledge_graph.png saved to working directory.

Printed performance summary (training samples, features, accuracy, F1).

Return values from hybrid_predict and diagnose_patient_condensed for integration.

Performance & evaluation

The script computes:

Top-1 accuracy — percent where top prediction matches true disease

Top-3 accuracy — percent where true disease is in top 3 predictions

Weighted F1 — class-weighted F1 score

These are printed after training. Keep in mind:

Metrics depend on the generated dataset; different random seeds or data variations will change results.

The KG adds interpretability and can correct ML in strong-match cases.

Troubleshooting

Missing JSON file: Ensure final_disease_symptoms_trimmed.json is present.

Memory issues during TF-IDF / training: If you run out of memory, reduce max_features in TfidfVectorizer or train on a smaller subset.

Slow training: Lower n_estimators or increase learning_rate temporarily for quick experiments.

Vectorizer/model persistence: Currently the script trains in-memory. To reuse models across runs, serialize tfidf and lgb_model using joblib or pickle.

Extending the project

Ideas for immediate extension:

Save / load trained artifacts (TF-IDF vectorizer + LightGBM model) for fast inference without retraining.

Add a symptom-normalization layer (synonym mapping, UMLS integration) to improve matching.

Add patient context features (age, duration, severity) to the numeric features for better discrimination.

Replace TF-IDF with contextual embeddings (e.g., ClinicalBERT) for better semantic matching.

Reproducibility / Notes

The script uses a fixed random seed (np.random.seed(42)) for sample generation and sampling to improve reproducibility.

Keep a copy of the original dataset and a copy of the script to reproduce results.

If you want exact run instructions or to generate a smaller training set for quick iterations, change samples_per_disease accordingly.
